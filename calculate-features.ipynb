{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from time import sleep\n",
    "from datetime import datetime as dt\n",
    "from natsort import natsorted\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams.update({'legend.fontsize': 'large',\n",
    "                     'axes.labelsize': 'large',\n",
    "                     'axes.titlesize': 'large',\n",
    "                     'xtick.labelsize': 'large',\n",
    "                     'ytick.labelsize': 'large'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRUPTED FILE: 'SE0000115446_SEK/8_SE0000115446_SEK_208.mat'\n",
    "corrupted = ['8_SE0000115446_SEK_208.mat']\n",
    "#sio.loadmat(corrupted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly start with file management. Filter out non-data directories, sort files in them to create big data files with needed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SE0000101032_SEK',\n",
       " 'SE0000115446_SEK',\n",
       " 'FI0009005318_EUR',\n",
       " 'FI0009007835_EUR',\n",
       " 'DK0010268606_DKK']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only needed directories \n",
    "dirs = [d for d in os.listdir('.') if os.path.isdir(os.path.join('.', d))]\n",
    "del dirs[1]\n",
    "del dirs[1]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz # to handle timezones\n",
    "\n",
    "\n",
    "# method to extract data from the order book\n",
    "def extract_order_book(path, deep=10):\n",
    "    # load data\n",
    "    mat = sio.loadmat(path)\n",
    "    order_book = mat['ob']\n",
    "\n",
    "    # time strip and convert to correct timezone\n",
    "    ts = pd.Series(order_book['ts'][0][0][:,0], name='ts')\n",
    "    ts = pd.to_datetime(ts, unit='ms') \n",
    "    ts = ts.dt.tz_localize('UTC').dt.tz_convert('Europe/Helsinki')\n",
    "    \n",
    "    # filter out pre-session and after-session data\n",
    "    f_ts = (ts.dt.hour > 8) & (ts.dt.hour < 18)\n",
    "    \n",
    "    # extract data to new data frame\n",
    "    df = pd.DataFrame(ts[f_ts]).reset_index(drop=True)\n",
    "    bidq = pd.DataFrame(order_book['bid_q'][0, 0][f_ts, :deep], columns=['bid_q' + str(i) for i in xrange(deep)])\n",
    "    bidp = pd.DataFrame(order_book['bid_p'][0, 0][f_ts, :deep], columns=['bid_p' + str(i) for i in xrange(deep)])\n",
    "    askq = pd.DataFrame(order_book['ask_q'][0, 0][f_ts, :deep], columns=['ask_q' + str(i) for i in xrange(deep)])\n",
    "    askp = pd.DataFrame(order_book['ask_p'][0, 0][f_ts, :deep], columns=['ask_p' + str(i) for i in xrange(deep)])\n",
    "    df = pd.concat([df, bidq, bidp, askq, askp], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort and save filenames\n",
    "f_names = []\n",
    "for d in dirs:\n",
    "    files = os.listdir(d)\n",
    "    f_names.append(natsorted(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in xrange(len(dirs)):\\n    d = dirs[i]\\n    files = f_names[i]\\n    n = len(files)\\n    \\n    for j, f in enumerate(files):\\n        \\n        # update progress\\n        sys.stdout.write(\"%s (%i/%i)\\t\\r\" % (d + \\'/\\' + f, j+1, n))\\n        sys.stdout.flush()\\n            \\n            \\n        # checks for bad files\\n        if not f.endswith(\\'.mat\\'):\\n            continue\\n        if f in corrupted:\\n            continue\\n            \\n        df = extract_order_book(d+\\'/\\'+f)\\n        with open(d+\\'.csv\\', \\'a\\') as w:\\n            df.to_csv(w, header=False, index=False)    \\n                \\n    break \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## HIDAS ÄLÄ AJA\n",
    "# filename: SE0000101032_SEK.csv\n",
    "\n",
    "'''\n",
    "for i in xrange(len(dirs)):\n",
    "    d = dirs[i]\n",
    "    files = f_names[i]\n",
    "    n = len(files)\n",
    "    \n",
    "    for j, f in enumerate(files):\n",
    "        \n",
    "        # update progress\n",
    "        sys.stdout.write(\"%s (%i/%i)\\t\\r\" % (d + '/' + f, j+1, n))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "            \n",
    "        # checks for bad files\n",
    "        if not f.endswith('.mat'):\n",
    "            continue\n",
    "        if f in corrupted:\n",
    "            continue\n",
    "            \n",
    "        df = extract_order_book(d+'/'+f)\n",
    "        with open(d+'.csv', 'a') as w:\n",
    "            df.to_csv(w, header=False, index=False)    \n",
    "                \n",
    "    break \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "header = ['date'] +\\\n",
    "         ['bid_q' + str(i) for i in xrange(1, 11)] +\\\n",
    "         ['bid_p' + str(i) for i in xrange(1, 11)] +\\\n",
    "         ['ask_q' + str(i) for i in xrange(1, 11)] +\\\n",
    "         ['ask_p' + str(i) for i in xrange(1, 11)]\n",
    "\n",
    "#import pandas as pd\n",
    "#pd_df = pd.read_csv('SE0000101032_SEK_test.csv')\n",
    "#del pd_df['Unnamed: 0']\n",
    "#pd_df.to_csv('SE0000101032_SEK_test.csv', index=False, header=header)\n",
    "#pd_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+------+------+------+------+------+------+------+-------+---------+\n",
      "|                date|bid_q1|bid_q2|bid_q3|bid_q4|bid_q5|bid_q6|bid_q7|bid_q8|bid_q9|bid_q10|   bid_p1|\n",
      "+--------------------+------+------+------+------+------+------+------+------+------+-------+---------+\n",
      "|2010-06-01 09:00:...| 500.0|  10.0| 663.0|3000.0| 600.0| 810.0|1000.0| 300.0| 450.0|10800.0|1110000.0|\n",
      "|2010-06-01 09:00:...| 500.0|  10.0| 663.0|3000.0| 600.0| 810.0|1000.0| 300.0| 450.0|10800.0|1110000.0|\n",
      "|2010-06-01 09:00:...| 500.0| 110.0| 663.0|3000.0| 600.0| 810.0|1000.0| 300.0| 450.0|10800.0|1110000.0|\n",
      "|2010-06-01 09:00:...| 500.0| 110.0| 200.0| 663.0|3000.0| 600.0| 810.0|1000.0| 300.0|  450.0|1110000.0|\n",
      "|2010-06-01 09:02:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:03:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:03:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:05:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:05:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:07:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:08:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:08:...| 500.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:08:...| 700.0| 110.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0|1000.0|  300.0|1110000.0|\n",
      "|2010-06-01 09:10:...| 700.0| 110.0| 180.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0| 1000.0|1110000.0|\n",
      "|2010-06-01 09:10:...| 700.0| 110.0| 180.0| 200.0|1000.0| 663.0|3000.0| 600.0| 810.0| 1000.0|1110000.0|\n",
      "|2010-06-01 09:20:...| 700.0| 110.0| 180.0| 200.0|1000.0| 663.0|3000.0| 600.0| 700.0|  810.0|1110000.0|\n",
      "|2010-06-01 09:27:...| 700.0| 110.0| 180.0| 200.0|1000.0| 663.0|3000.0| 600.0| 700.0|  810.0|1110000.0|\n",
      "|2010-06-01 09:29:...| 700.0| 110.0| 180.0| 200.0|1000.0| 663.0|3000.0| 600.0| 700.0|  810.0|1110000.0|\n",
      "|2010-06-01 09:33:...| 700.0| 110.0| 180.0| 200.0|1000.0| 663.0|3000.0| 600.0| 700.0|  810.0|1110000.0|\n",
      "|2010-06-01 09:44:...| 700.0| 110.0| 180.0| 200.0|1000.0| 510.0| 663.0|3000.0| 600.0|  700.0|1110000.0|\n",
      "+--------------------+------+------+------+------+------+------+------+------+------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").options(header=\"true\", \n",
    "                                      inferSchema=\"true\",\n",
    "                                      dateFormat=\"yyyy-MM-dd HH:mm:ss\")\\\n",
    "            .load(\"file:///home/janne/Thesis/Data/SE0000101032_SEK_test.csv\")\n",
    "df.select(df.columns[:12]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|  ask_p10|  mean_p1|  mean_p2|  mean_p3|  mean_p4|  mean_p5|  mean_p6|  mean_p7|  mean_p8|  mean_p9| mean_p10|\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|1165000.0|1119000.0|1115000.0|1102500.0|1101000.0|1097500.0|1090500.0|1092500.0|1091500.0|1092500.0|1092500.0|\n",
      "|1165000.0|1119000.0|1115000.0|1102500.0|1101000.0|1097500.0|1090500.0|1092500.0|1091500.0|1092500.0|1092500.0|\n",
      "|1165000.0|1119000.0|1115000.0|1102500.0|1101000.0|1097500.0|1090500.0|1092500.0|1091500.0|1092500.0|1092500.0|\n",
      "|1165000.0|1119000.0|1115000.0|1115000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|1095000.0|\n",
      "|1165000.0|1119000.0|1115000.0|1115000.0|1111000.0|1104000.0|1102500.0|1101000.0|1094500.0|1097500.0|1097500.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1093000.0|1094000.0|1095000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1114000.0|1115000.0|1111000.0|1104000.0|1102500.0|1101000.0|1094500.0|1097500.0|\n",
      "|1160000.0|1114000.0|1114000.0|1114000.0|1115000.0|1111000.0|1104000.0|1102500.0|1101000.0|1094500.0|1097500.0|\n",
      "|1160000.0|1114000.0|1114000.0|1114000.0|1115000.0|1111000.0|1104000.0|1102500.0|1101000.0|1101500.0|1098000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1114000.0|1115000.0|1111000.0|1104000.0|1102500.0|1101000.0|1101500.0|1098000.0|\n",
      "|1160000.0|1114000.0|1114000.0|1114000.0|1115000.0|1111000.0|1104000.0|1102500.0|1101000.0|1101500.0|1098000.0|\n",
      "|1153000.0|1114000.0|1110500.0|1113000.0|1110000.0|1110000.0|1103500.0|1101500.0|1098500.0|1100000.0|1094500.0|\n",
      "|1153000.0|1114000.0|1110500.0|1113000.0|1110000.0|1110000.0|1105000.0|1104000.0|1102500.0|1101000.0|1101500.0|\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate Mid-Prices per price level\n",
    "for i in xrange(1, 11):\n",
    "    marksColumns = [col('bid_p' + str(i)), col('ask_p' + str(i))]\n",
    "    averageFunc = sum(x for x in marksColumns)/len(marksColumns)\n",
    "    \n",
    "    df = df.withColumn('mean_p' + str(i), averageFunc)\n",
    "        \n",
    "df.select(df.columns[40:]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+\n",
      "| mean_p10|spread_p1|spread_p2|spread_p3|spread_p4|spread_p5|spread_p6|spread_p7|spread_p8|spread_p9|spread_p10|\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+\n",
      "|1092500.0|  18000.0|  30000.0|  75000.0|  82000.0|  91000.0| 109000.0| 115000.0| 123000.0| 135000.0|  145000.0|\n",
      "|1092500.0|  18000.0|  30000.0|  75000.0|  82000.0|  91000.0| 109000.0| 115000.0| 123000.0| 135000.0|  145000.0|\n",
      "|1092500.0|  18000.0|  30000.0|  75000.0|  82000.0|  91000.0| 109000.0| 115000.0| 123000.0| 135000.0|  145000.0|\n",
      "|1095000.0|  18000.0|  30000.0|  50000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0| 130000.0|  140000.0|\n",
      "|1097500.0|  18000.0|  30000.0|  50000.0|  62000.0|  78000.0|  85000.0|  98000.0| 117000.0| 125000.0|  135000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1095000.0|   8000.0|  28000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 114000.0| 118000.0|  130000.0|\n",
      "|1097500.0|   8000.0|  28000.0|  32000.0|  50000.0|  62000.0|  78000.0|  85000.0|  98000.0| 117000.0|  125000.0|\n",
      "|1097500.0|   8000.0|  28000.0|  32000.0|  50000.0|  62000.0|  78000.0|  85000.0|  98000.0| 117000.0|  125000.0|\n",
      "|1098000.0|   8000.0|  28000.0|  32000.0|  50000.0|  62000.0|  78000.0|  85000.0|  98000.0| 103000.0|  124000.0|\n",
      "|1098000.0|   8000.0|  28000.0|  32000.0|  50000.0|  62000.0|  78000.0|  85000.0|  98000.0| 103000.0|  124000.0|\n",
      "|1098000.0|   8000.0|  28000.0|  32000.0|  50000.0|  62000.0|  78000.0|  85000.0|  98000.0| 103000.0|  124000.0|\n",
      "|1094500.0|   8000.0|  21000.0|  30000.0|  40000.0|  60000.0|  77000.0|  83000.0|  93000.0| 100000.0|  117000.0|\n",
      "|1101500.0|   8000.0|  21000.0|  30000.0|  40000.0|  60000.0|  74000.0|  78000.0|  85000.0|  98000.0|  103000.0|\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate spreads per price level\n",
    "for i in xrange(1, 11):\n",
    "    df = df.withColumn('spread_p' + str(i), col('ask_p' + str(i)) - col('bid_p' + str(i)))\n",
    "    \n",
    "df.select(df.columns[50:]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|ask_diff5|ask_diff6|ask_diff7|ask_diff8|ask_diff9|bid_diff1|bid_diff2|bid_diff3|bid_diff4|bid_diff5|\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "|   2000.0|   5000.0|   3000.0|   7000.0|   5000.0|  10000.0|  35000.0|   5000.0|   8000.0|  16000.0|\n",
      "|   2000.0|   5000.0|   3000.0|   7000.0|   5000.0|  10000.0|  35000.0|   5000.0|   8000.0|  16000.0|\n",
      "|   2000.0|   5000.0|   3000.0|   7000.0|   5000.0|  10000.0|  35000.0|   5000.0|   8000.0|  16000.0|\n",
      "|   2000.0|   5000.0|   3000.0|   7000.0|   5000.0|  10000.0|  10000.0|  25000.0|   5000.0|   8000.0|\n",
      "|   2000.0|   5000.0|   3000.0|   7000.0|   5000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|  10000.0|  10000.0|  15000.0|   5000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|   2000.0|   8000.0|  10000.0|  15000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|   2000.0|   8000.0|  10000.0|  15000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|   2000.0|   8000.0|  10000.0|  15000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|   2000.0|   8000.0|  10000.0|  15000.0|\n",
      "|   1000.0|   2000.0|   5000.0|   3000.0|   7000.0|  10000.0|   2000.0|   8000.0|  10000.0|  15000.0|\n",
      "|   2000.0|   1000.0|   2000.0|   5000.0|   3000.0|  10000.0|   2000.0|   8000.0|  10000.0|  15000.0|\n",
      "|   2000.0|   1000.0|   2000.0|   5000.0|   3000.0|  10000.0|   2000.0|   8000.0|  10000.0|  12000.0|\n",
      "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# calculate price differences for subsequent asking and bidding prices\n",
    "# ask\n",
    "for i in xrange(1, 10):\n",
    "    df = df.withColumn('ask_diff' + str(i), F.abs(col('ask_p' + str(i+1)) - col('ask_p' + str(i))))\n",
    "\n",
    "# bid\n",
    "for i in xrange(1, 10):\n",
    "    df = df.withColumn('bid_diff' + str(i), F.abs(col('bid_p' + str(i+1)) - col('bid_p' + str(i))))\n",
    "\n",
    "\n",
    "df.select(df.columns[65:75]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+----------+---------+---------+---------+---------+\n",
      "|bid_diff6|bid_diff7|bid_diff8|bid_diff9|mean_price|mean_bidp|mean_askp|mean_bidv|mean_askv|\n",
      "+---------+---------+---------+---------+----------+---------+---------+---------+---------+\n",
      "|   1000.0|   5000.0|   5000.0|   5000.0| 1053300.0|1053300.0|1053300.0|1053300.0|1053300.0|\n",
      "|   1000.0|   5000.0|   5000.0|   5000.0| 1053300.0|1053300.0|1053300.0|1053300.0|1053300.0|\n",
      "|   1000.0|   5000.0|   5000.0|   5000.0| 1053300.0|1053300.0|1053300.0|1053300.0|1053300.0|\n",
      "|  16000.0|   1000.0|   5000.0|   5000.0| 1060300.0|1060300.0|1060300.0|1060300.0|1060300.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   8000.0|  16000.0|   1000.0|   5000.0| 1065800.0|1065800.0|1065800.0|1065800.0|1065800.0|\n",
      "|   5000.0|   8000.0|  16000.0|   1000.0| 1072600.0|1072600.0|1072600.0|1072600.0|1072600.0|\n",
      "|   5000.0|   8000.0|  16000.0|   1000.0| 1072600.0|1072600.0|1072600.0|1072600.0|1072600.0|\n",
      "|   5000.0|   8000.0|   2000.0|  14000.0| 1074100.0|1074100.0|1074100.0|1074100.0|1074100.0|\n",
      "|   5000.0|   8000.0|   2000.0|  14000.0| 1074100.0|1074100.0|1074100.0|1074100.0|1074100.0|\n",
      "|   5000.0|   8000.0|   2000.0|  14000.0| 1074100.0|1074100.0|1074100.0|1074100.0|1074100.0|\n",
      "|   5000.0|   8000.0|   2000.0|  14000.0| 1074100.0|1074100.0|1074100.0|1074100.0|1074100.0|\n",
      "|   3000.0|   5000.0|   8000.0|   2000.0| 1077300.0|1077300.0|1077300.0|1077300.0|1077300.0|\n",
      "+---------+---------+---------+---------+----------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marksColumns = [col('bid_p' + str(i)) for i in xrange(1, 11)]\n",
    "df = df.withColumn('mean_bidp', averageFunc)\n",
    "\n",
    "marksColumns = [col('ask_p' + str(i)) for i in xrange(1, 11)]\n",
    "df = df.withColumn('mean_askp', averageFunc)\n",
    "\n",
    "marksColumns = [col('bid_v' + str(i)) for i in xrange(1, 11)]\n",
    "df = df.withColumn('mean_bidv', averageFunc)\n",
    "\n",
    "marksColumns = [col('ask_v' + str(i)) for i in xrange(1, 11)]\n",
    "df = df.withColumn('mean_askv', averageFunc)\n",
    "\n",
    "df.select(df.columns[75:]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
